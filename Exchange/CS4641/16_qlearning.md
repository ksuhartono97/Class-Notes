# Q-Learning
Decaying epsilon greedy similar to simulated annealing, the idea is that we want to explore more early on, and do the more optimal thing a lot more later on.

Q-learning lets us get away with not executing every single state unlike value iteration or policy iteration.

Q-learning problems:
- Can get stuck in terrible negative local maximas (mario example, takes a long time to learn how to jump)

Exercise:
- Value Iteration
- Q-Learning
- Value Iteration

Deep RL: replace agent with a deep NN

Idea is we want to generalize the agent's choices more. 
