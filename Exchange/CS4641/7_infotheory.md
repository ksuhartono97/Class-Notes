# Entropy

Entropy exercise on number of bits needed to represent:

Use a bit representation for the inputs.

## Variable Length Encoding
Memory to store symbol inversely related to its frequency. Messages can store different encoding schemes.

Generally speaking, entropy can be thought of as the opposite of probability.

> T-testing is often used, but should only use when the data is in a normal distribution.

> Wilcox testing is another test that can be used to check the "distance" between two models, data doesn't need to be in a normal distribution.

Ex 2:
```
Describe the perfomance? Variance and standard deviation? High variance and SD could mean a worse performance.
```

Ex 3:
```
Bias should be high since we only look at people who actually exercise  
Variance should be low since these people are already in the gym

Sample error is low
True error would be high.
```

## Confidence Interval
Sort of the upper and lower bound to 
